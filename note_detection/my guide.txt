mport 'package:flutter/material.dart';
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:image_picker/image_picker.dart'; // For picking images from the device

class ImageClassifier extends StatefulWidget {
  @override
  _ImageClassifierState createState() => _ImageClassifierState();
}

class _ImageClassifierState extends State<ImageClassifier> {
  Interpreter? interpreter;
  List<String> labels = [];
  bool isLoading = false;
  late ImagePicker picker;

  @override
  void initState() {
    super.initState();
    picker = ImagePicker();
    loadModel();
  }

  Future<void> loadModel() async {
    interpreter = await Interpreter.fromAsset('model.tflite');
    var labelsFile = await DefaultAssetBundle.of(context).loadString('assets/labels.txt');
    labels = labelsFile.split('\n').map((String label) => label.trim()).toList();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text('Image Classifier'),
      ),
      body: isLoading
          ? CircularProgressIndicator()
          : Center(
              child: ElevatedButton(
                onPressed: classifyImage,
                child: Text('Classify Image'),
              ),
            ),
    );
  }

  Future<void> classifyImage() async {
    setState(() {
      isLoading = true;
    });
    
    try {
      XFile? image = await picker.pickImage(source: ImageSource.gallery);
      if (image == null) return;

      var inputBytes = await image.readAsBytes();
      var inputTensors = [inputBytes];

      var outputTensors = List.filled(1, Float64List(1000)); // Adjust the size based on your model output
      interpreter?.run(inputTensors, outputTensors);

      var output = outputTensors[0];
      var maxIndex = output.indexOf(output.reduce((curr, next) => curr > next ? curr : next));
      var result = labels[maxIndex];

      print('Classification result: $result');
    } catch (e) {
      print('Error classifying image: $e');
    } finally {
      setState(() {
        isLoading = false;
      });
    }
  }
}

void main() {
  runApp(MaterialApp(home: ImageClassifier()));
}
here is the code from the .py file got from what was used # -- coding: utf-8 --
"""Transfer learning .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L_4vwgLKAo1SJCk9fYHzWWwy4EAH2ntO

Mounting drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""## All necessary imports"""

import os
import keras
import numpy as np
import tensorflow as tf
import pandas as pd
import seaborn as sbn
sbn.set()


# Data
from keras.preprocessing.image import ImageDataGenerator

# Data Visualization
import plotly.express as px
import matplotlib.pyplot as plt

# Model
from keras.models import Sequential, load_model
from keras.layers import GlobalAvgPool2D as GAP, Dense, Dropout

# Callbacks
from keras.callbacks import EarlyStopping, ModelCheckpoint

# Pre-Trained Model
from tensorflow.keras.applications import ResNet50, ResNet50V2, InceptionV3, Xception, ResNet152, ResNet152V2

"""## Data analysis

*Data structure*
"""

import os

root_path = '/content/drive/MyDrive/Detection of UG counterfeit Banknotes/dataset/train_set'
class_names = sorted([name for name in os.listdir(root_path) if not name.startswith('.')])  # Skip hidden files
n_classes = len(class_names)

# Class Distribution
class_dis = [len(os.listdir(os.path.join(root_path, name))) for name in class_names]

# Show
print(f"Total Number of Classes : {n_classes}\nClass Names : {class_names}")
class_dis

""" *Class Distribution*"""

# Visualize
data = {'Class Names': class_names, 'Class Distribution': class_dis}
df = pd.DataFrame(data)

# plt.figure(figsize=(10, 10))
df.plot.pie(y='Class Distribution', labels=df['Class Names'], autopct='%1.1f%%', startangle=200)
plt.title('Class Distribution')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.show()

"""# *Data Loading*"""

from keras.preprocessing.image import ImageDataGenerator

# Initialize Generator
train_gen = ImageDataGenerator(rescale=1/255., rotation_range=10)
valid_gen = ImageDataGenerator(rescale=1/255.)
test_gen = ImageDataGenerator(rescale=1/255.)

# Load Data
train_ds = train_gen.flow_from_directory(root_path, class_mode='binary', target_size=(224,224), shuffle=True, batch_size=32)
valid_ds = valid_gen.flow_from_directory(root_path.replace('train_set','validation_set'), class_mode='binary', target_size=(224,224), shuffle=True, batch_size=32)
test_ds = test_gen.flow_from_directory(root_path.replace('train_set', 'test_set'), class_mode='binary', target_size=(224,224), shuffle=True, batch_size=32)

"""# *Data Visualization*"""

def show_images(GRID=[5,5], model=None, size=(20,20), data=test_ds):
    n_rows, n_cols = GRID
    n_images = n_rows * n_cols

    # Initialize an iterator for the data
    data_iterator = iter(data)

    plt.figure(figsize=size)

    for i in range(n_images):
        try:
            # Get the next batch of images and labels
            images, labels = next(data_iterator)
        except StopIteration:
            print("Error: No more data batches available.")
            break

        batch_size = len(images)
        if batch_size == 0:
            print("Error: Empty batch.")
            break

        for j in range(batch_size):
            # Display the image
            if i < n_rows * n_cols:
                plt.subplot(n_rows, n_cols, i + 1)
                plt.imshow(images[j])

                # Add title with class information
                try:
                    label_index = int(labels[j])
                    if 0 <= label_index < len(class_names):
                        if model is None:
                            title = f"Class: {class_names[label_index]}"
                        else:
                            pred = class_names[int(np.argmax(model.predict(images[j][np.newaxis, ...])))]
                            title = f"Org: {class_names[label_index]}, Pred: {pred}"
                        plt.title(title)
                    else:
                        plt.title("Invalid Class Index")
                except IndexError:
                    plt.title("Index Error")

                plt.axis('off')

            i += 1
            if i >= n_images:
                break

    plt.tight_layout()
    plt.show()

show_images()

"""# *Model*"""

# Pre-Trained Model
from tensorflow.keras.applications import ResNet50, ResNet50V2, InceptionV3, Xception, ResNet152, ResNet152V2
base_model = ResNet152V2(input_shape=(224, 224, 3), include_top=False)
base_model.trainable = False

# Model Architecture
from keras.models import Sequential
from keras.layers import GlobalAveragePooling2D, Dense

name = "ResNet152V2"
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu', kernel_initializer='he_normal'),
    Dense(n_classes, activation='softmax')
], name=name)

# Callbacks
from keras.callbacks import EarlyStopping, ModelCheckpoint

cbs = [EarlyStopping(patience=3, restore_best_weights=True), ModelCheckpoint(name + ".h5", save_best_only=True)]

# Model Compiling
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model Training
history = model.fit(train_ds, validation_data=valid_ds, callbacks=cbs, epochs=50, verbose=1)

pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()
plt.title('Accuracy')
plt.show()

pd.DataFrame(history.history)[['loss','val_loss']].plot()
plt.title('Loss')
plt.show()

# Move the model to Google Drive
!cp 'ResNet152V2.h5' '/content/drive/MyDrive/Detection of UG counterfeit Banknotes/notes analysis/models/'

"""# *Evaluation*"""

# Evaluation on test Set
from keras.models import Sequential, load_model
model_path = "/content/drive/MyDrive/Detection of UG counterfeit Banknotes/notes analysis/models/ResNet152V2.h5"
model = load_model(model_path)

# Architecture
model.summary()

model.evaluate(train_ds)

# Visualize Predictions
show_images(model=model, data=valid_ds)

"""### *Confusion matrix*"""

import numpy as np
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

# Load the best saved model
best_model = load_model("ResNet152V2.h5")

# Evaluate the model on the test dataset
test_loss, test_accuracy = best_model.evaluate(test_ds, verbose=1)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

# Get predictions for the test dataset
test_images, test_labels = next(test_ds)
predictions = best_model.predict(test_images)
predicted_labels = np.argmax(predictions, axis=1)

# Calculate accuracy
accuracy = accuracy_score(test_labels, predicted_labels)
print("Accuracy:", accuracy)

# Generate classification report
print("Classification Report:")
print(classification_report(test_labels, predicted_labels))

# Generate confusion matrix
conf_matrix = confusion_matrix(test_labels, predicted_labels)
print("Confusion Matrix:")
print(conf_matrix)

def plot_conf_mat(y,y_pred):
    from sklearn.metrics import confusion_matrix
    cm = confusion_matrix(y,y_pred)
    ax = plt.subplot()
    sns.heatmap(cm,annot = True,cmap='Blues' ,ax = ax)
    sns.heatmap(cm, annot=True,cmap='Blues', ax = ax); #annot=True to annotate cells
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title('Confusion Matrix');
    ax.set_xticklabels(['counterfeit', 'genuine'])
    ax.set_yticklabels(['counterfeit', 'genuine'])
    plt.show()
plot_conf_mat(test_labels,predicted_labels)

show_images(model=model, data=test_ds)

"""Receiver Operating Curve"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from keras.utils import to_categorical

# Assuming 'model' is your trained model
y_pred_prob = model.predict(test_ds)
y_true = np.array([y for _, y in test_ds])

# Convert the true labels to one-hot encoding
y_true_one_hot = to_categorical(y_true, num_classes=n_classes)

# Plot ROC curves
plt.figure(figsize=(10, 8))

for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_true_one_hot[:, i], y_pred_prob[:, i])
    roc_auc = auc(fpr, tpr)

    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Each Class')
plt.legend()
plt.show()
import 'package:tflite_flutter/tflite_flutter.dart';
import 'package:image/image.dart' as img;

// Load the TFLite model
Future<void> loadModel() async {
  TfliteFlutter.addNativeMethod('predict', (parameters) async {
    // Get input binary data from parameters
    Float32List inputData = parameters['binary'];
    
    // Run inference
    var output = await Tflite.runModelOnBinary(
      binary: inputData,
      numResults: 1, // Number of results to return
    );

    // Return output
    return output;
  });

  await TfliteFlutter.loadModel(
    model: 'assets/model.tflite', // Path to your TFLite model file
  );
}

// Function to classify an image
Future<String> classifyImage(String imagePath) async {
  // Load and preprocess the image
  var imageBytes = img.decodeImage(File(imagePath).readAsBytesSync());
  var inputImage = img.copyResize(imageBytes, width: 224, height: 224);
  var inputImageData = Float32List(224 * 224 * 3);
  for (var i = 0; i < 224; i++) {
    for (var j = 0; j < 224; j++) {
      var pixel = inputImage.getPixel(j, i);
      inputImageData[i * 224 * 3 + j * 3 + 0] = (img.getRed(pixel) - 127.5) / 127.5;
      inputImageData[i * 224 * 3 + j * 3 + 1] = (img.getGreen(pixel) - 127.5) / 127.5;
      inputImageData[i * 224 * 3 + j * 3 + 2] = (img.getBlue(pixel) - 127.5) / 127.5;
    }
  }

  // Perform inference
  var output = await TfliteFlutter.runModelOnBinary(binary: inputImageData);

  // Process the output
  var predictedLabel = output[0]['label'];

  return predictedLabel;
}

// Example usage
void main() async {
  var imagePath = "path_to_your_image.jpg";
  await loadModel();
  var predictedClass = await classifyImage(imagePath);
  print("Predicted class: $predictedClass");
}
import 'dart:io';
import 'dart:typed_data';

import 'package:flutter/material.dart';
import 'package:tflite_flutter/tflite_flutter.dart';

class Ourclasifier extends ChangeNotifier {
  bool classifying = false;
  bool initialised = false;
  List<String> labels = ["counterfeit", "Genuine"];
  Interpreter interpreter =
      Interpreter.fromAsset('assets/model/ResNet50V2.tflite') as Interpreter;
  final List<File> _selectedimages = [];
  List<File> _copySelectedImages = [];
  List<Uint8List> _imagesAsbytes = [];
  List<int> changed = [];
  List<String> classification = [];

  Future<void> doByteConvession() async {
    if (_selectedimages.isEmpty) {
      _imagesAsbytes = _selectedimages
          .map((File element) async {
            return await element.readAsBytes();
          })
          .cast<Uint8List>()
          .toList();
      _copySelectedImages = List.from(_selectedimages);
      notifyListeners();
    }
    for (int i = 0; i < _selectedimages.length; i++) {
      if (_selectedimages[i] != _copySelectedImages[i]) {
        _imagesAsbytes[i] = await _selectedimages[i].readAsBytes();
        changed.add(i);
        notifyListeners();

        // _imagesAsbytes.replaceRange(i-1, i, _selectedimages[i].readAsBytes() as List<Uint8List>)
      }
    }
  }

  Future<void> initialise() async {
    if (!initialised) {
      interpreter =
          await Interpreter.fromAsset('assets/model/ResNet50V2.tflite');
    }
    initialised = true;
    return;
  }

Future<void> classifyImages(bool isChanged) async {
  classifying = true;
  if (!initialised) {
    await initialise();
  }
  if (isChanged) {
    for (Uint8List x in _imagesAsbytes) {
      // var inputBytes = await image.readAsBytes();
      var inputTensors = [x];

      var outputTensors = List.filled(
          1, Float64List(1000)); // Adjust the size based on your model output
      interpreter.run(inputTensors, outputTensors);

      var output = outputTensors[0];
      var maxIndex = output
          .indexOf(output.reduce((curr, next) => curr > next ? curr : next));
       classification [_imagesAsbytes.indexOf(x)] = labels[maxIndex];
       notifyListeners();
    }
  }
}
import 'package:tflite_flutter/tflite_flutter.dart';

// Load the TFLite model
Future<void> loadModel() async {
  await Tflite.loadModel(
    model: 'assets/model.tflite', // Path to your TFLite model file
    labels: 'assets/labels.txt',  // Path to your labels file
  );
}

// Function to classify an image
Future<String> classifyImage(String imagePath) async {
  // Perform inference
  var output = await Tflite.runModelOnImage(
    path: imagePath,
    numResults: 1, // Number of results to return
  );

  // Process the output
  var predictedLabel = output[0]['label'];

  return predictedLabel;
}

// Example usage
void main() async {
  var imagePath = "path_to_your_image.jpg";
  await loadModel();
  var predictedClass = await classifyImage(imagePath);
  print("Predicted class: $predictedClass");
}